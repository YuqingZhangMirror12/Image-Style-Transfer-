{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast neural style transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv2oKmF9AJtI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA2-UyfpEc9O"
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"/content/gdrive/My Drive/Colab Notebooks/StyleTransfer\"):\n",
        "    os.makedirs(\"/content/gdrive/My Drive/Colab Notebooks/StyleTransfer\")\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/StyleTransfer\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyRCWAIyRHWc"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlyCnvf6WzjR"
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iqJ9ZTBImtv",
        "outputId": "d4a14c58-5bc5-4604-af3e-43405368aff6"
      },
      "source": [
        "#Vgg16 Model\n",
        "class Vgg(nn.Module):\n",
        "    def __init__(self, requires_grad=False):\n",
        "        super(Vgg, self).__init__()\n",
        "        features = models.vgg16(pretrained=True).features\n",
        "        #separate 4 blocks of VGG16\n",
        "\n",
        "        self.f1 = nn.Sequential(*(list(features.children())[0:4]))\n",
        "        self.f2 = nn.Sequential(*(list(features.children())[4:9]))\n",
        "        self.f3 = nn.Sequential(*(list(features.children())[9:16]))\n",
        "        self.f4 = nn.Sequential(*(list(features.children())[16:23]))\n",
        "        \n",
        "        if requires_grad == False:\n",
        "            for p in self.parameters():\n",
        "                p.requires_grad = False\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.f1(x)\n",
        "        relu1_2 = x1\n",
        "        x2 = self.f2(x1)\n",
        "        relu2_2 = x2\n",
        "        x3 = self.f3(x2)\n",
        "        relu3_3 = x3\n",
        "        x4 = self.f4(x3)\n",
        "        relu4_3 = x4\n",
        "       \n",
        "        output = [relu1_2, relu2_2, relu3_3, relu4_3]\n",
        "        return output\n",
        "Vgg()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vgg(\n",
              "  (f1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (f2): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "  )\n",
              "  (f3): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "  )\n",
              "  (f4): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN4KDn8TIRjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8c4cc0-a466-4b21-ef75-c7434807f31f"
      },
      "source": [
        "#Transformation Network\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Block for implementation of Residual connection\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        #2 layers of 3x3 convolutional layers\n",
        "        self.conv1 = nn.Sequential(\n",
        "          nn.ReflectionPad2d(3//2),\n",
        "          nn.Conv2d(c, c, kernel_size=3, stride=1),\n",
        "          nn.InstanceNorm2d(c, affine=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "          nn.ReflectionPad2d(3//2),\n",
        "          nn.Conv2d(c, c, kernel_size=3, stride=1),\n",
        "          nn.InstanceNorm2d(c, affine=True)\n",
        "        )\n",
        "\n",
        "      \n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "\n",
        "        x1 = self.conv1(x)    \n",
        "        x1= self.relu(x1)\n",
        "        x1 = self.conv2(x1)\n",
        "\n",
        "        x1 = x1 + res\n",
        "        return x1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        # conv layers\n",
        "        self.conv1 =nn.Sequential(  \n",
        "          nn.ReflectionPad2d(9//2),\n",
        "          nn.Conv2d(3, 32, kernel_size=9, stride=1),\n",
        "          nn.InstanceNorm2d(32, affine=True),\n",
        "          nn.ReLU()    \n",
        "        )\n",
        "\n",
        "        #2 upsample layers\n",
        "        self.conv2 = nn.Sequential(\n",
        "          nn.ReflectionPad2d(3//2),\n",
        "          nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
        "          nn.InstanceNorm2d(64, affine=True),\n",
        "          nn.ReLU() \n",
        "            \n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "          nn.ReflectionPad2d(3//2),\n",
        "          nn.Conv2d(64, 128, kernel_size=3, stride=2),\n",
        "          nn.InstanceNorm2d(128, affine=True),\n",
        "          nn.ReLU() \n",
        "            \n",
        "        )\n",
        "\n",
        "        # 5 layers of residual block\n",
        "        self.res = nn.Sequential(\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128)\n",
        "            \n",
        "        )\n",
        "        # 2 downsample layers\n",
        "        self.conv4 = nn.Sequential(\n",
        "          nn.Upsample(mode='nearest', scale_factor=2.0),\n",
        "          nn.ReflectionPad2d(3//2),\n",
        "          nn.Conv2d(128, 64, kernel_size=3, stride=1),\n",
        "          nn.InstanceNorm2d(64, affine=True),\n",
        "          nn.ReLU() \n",
        "            \n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "          nn.Upsample(mode='nearest', scale_factor=2.0),\n",
        "          nn.ReflectionPad2d(3//2),\n",
        "          nn.Conv2d(64, 32, kernel_size=3, stride=1),\n",
        "          nn.InstanceNorm2d(32, affine=True),\n",
        "          nn.ReLU() \n",
        "            \n",
        "        )\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "          torch.nn.ReflectionPad2d(9//2),\n",
        "          torch.nn.Conv2d(32, 3, kernel_size=9, stride=1), \n",
        "          )\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.res(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "       \n",
        "        return x\n",
        "\n",
        "\n",
        "Transformer()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (conv1): Sequential(\n",
              "    (0): ReflectionPad2d((4, 4, 4, 4))\n",
              "    (1): Conv2d(3, 32, kernel_size=(9, 9), stride=(1, 1))\n",
              "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (res): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    (1): ReflectionPad2d((1, 1, 1, 1))\n",
              "    (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (conv5): Sequential(\n",
              "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    (1): ReflectionPad2d((1, 1, 1, 1))\n",
              "    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (conv6): Sequential(\n",
              "    (0): ReflectionPad2d((4, 4, 4, 4))\n",
              "    (1): Conv2d(32, 3, kernel_size=(9, 9), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCu9Qd0PIZBO"
      },
      "source": [
        "def normalize(img):\n",
        "    # normalize the transformed image with mean and std\n",
        "    im_std = img.new_tensor([0.229, 0.224, 0.225]).view( -1, 1, 1)\n",
        "    im_mean = img.new_tensor([0.485, 0.456, 0.406]).view( -1, 1, 1)\n",
        "      \n",
        "    img = img.div_(255.0)\n",
        "    v = (img - im_mean)/im_std\n",
        "    return v\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUf4nsGT_lOD"
      },
      "source": [
        "def calculate_gram_matrix(input):\n",
        "  '''\n",
        "  A function to calcuate the gram matrix\n",
        "  '''\n",
        "  a, c, h, w = input.size()\n",
        "\n",
        "  feature = input.view(a, c, w*h)\n",
        "  feature_T = feature.transpose(1, 2)\n",
        "  gram = feature.bmm(feature_T)\n",
        "  gram /=  (c*h*w)\n",
        "\n",
        "  return gram"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBuZ4gFbJQA1"
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "batch_size = 4\n",
        "epochs =2\n",
        "dataset_path = \"./train2014\"\n",
        "style_image_path =\"./input/Mona_Lisa.jpg\"\n",
        "save_path =\"./output\"\n",
        "\n",
        "feature_w = 1e5\n",
        "style_w = 1e10\n",
        "\n",
        "np.random.seed(50)\n",
        "torch.manual_seed(50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb_IR2qLIz_Q"
      },
      "source": [
        "# Model training\n",
        "def train():   \n",
        "    # Need to resize to 3x256x256\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x:x.mul(255))\n",
        "    ])\n",
        "\n",
        "    style_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.mul(255))\n",
        "    ])\n",
        "\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(dataset_path, transform= transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size= batch_size)\n",
        "\n",
        "    model = Transformer().to(device)\n",
        "    vgg = Vgg(requires_grad=False).to(device)\n",
        "\n",
        "    style = Image.open(style_image_path)\n",
        "    style = style_transform(style)\n",
        "\n",
        "    style = style.repeat(batch_size, 1, 1, 1)\n",
        "    style = style.to(device)\n",
        "    style = normalize(style)\n",
        "\n",
        "    style_feature = vgg(style)\n",
        "    #get gram matrix for style\n",
        "    style_gram =[]\n",
        "    for f in style_feature:\n",
        "        style_gram.append(calculate_gram_matrix(f))\n",
        "    \n",
        "    \n",
        "    \n",
        "    loss = nn.MSELoss()\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "    \n",
        "\n",
        "    for e in range(epochs):\n",
        "        print(\"start epoch \",e)\n",
        "        model.train()\n",
        "\n",
        "        for l, batch in enumerate(tqdm(train_loader)):\n",
        "            #print(\"start batch \", batch_id)\n",
        "            img = batch[0] \n",
        "            sz =  len(img)  \n",
        "           \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            img = img.to(device)\n",
        "            trans = model(img)\n",
        "\n",
        "            # Normalize images\n",
        "            trans = normalize(trans)\n",
        "            img = normalize(img)\n",
        "\n",
        "            trans_feature = vgg(trans)\n",
        "            img_feature = vgg(img)\n",
        "\n",
        "            #get relu3_3\n",
        "            feature_loss =loss(trans_feature[2], img_feature[2])\n",
        "\n",
        "            style_loss = 0.0\n",
        "\n",
        "            #Calculate gram matrix, sum of relu1_2, relu2_2, relu3_3, relu4_3\n",
        "            for i in range(len(trans_feature)):\n",
        "                trans_gram = calculate_gram_matrix(trans_feature[i])\n",
        "                style_loss += loss(trans_gram, style_gram[i][:sz])\n",
        "            \n",
        "            #multiply the weight\n",
        "            feature_loss *= feature_w\n",
        "            style_loss *= style_w\n",
        "\n",
        "            total_loss = feature_loss + style_loss\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "                \n",
        "    print(\"Training done\")\n",
        "          \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxqNt44qPREv"
      },
      "source": [
        "#Start training\n",
        "model = train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnrNQfZeMTPf"
      },
      "source": [
        "#Image Style Transformation using model\n",
        "\n",
        "content_path =\"./input/bobo.jpg\"\n",
        "save_result_path = \"./output.jpg\"\n",
        "\n",
        "content = Image.open(content_path)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x:x.mul(255))\n",
        "    ])\n",
        "\n",
        "content = transform(content)\n",
        "content = content.unsqueeze(0)\n",
        "content= content.to(device)\n",
        "\n",
        "with torch.no_grad():  \n",
        "    model.to(device)\n",
        "    output = model(content)\n",
        "    output = output.cpu()\n",
        "    plt.figure()\n",
        "    img = (output[0].clamp(0, 255).numpy().transpose(1, 2, 0)).astype(\"uint8\")\n",
        "    plt.imshow(img)\n",
        "    #save image\n",
        "    Image.fromarray(img).save(save_result_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}